{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4eafa0e-1bce-404b-bd40-ad17f1bf4038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T14:58:21.763521Z",
     "iopub.status.busy": "2025-02-24T14:58:21.763347Z",
     "iopub.status.idle": "2025-02-24T14:58:34.220596Z",
     "shell.execute_reply": "2025-02-24T14:58:34.219994Z",
     "shell.execute_reply.started": "2025-02-24T14:58:21.763503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.140.84.29:46082\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>zhangwenwei-math-page-parse</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f93080c91b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create spark session\n",
    "from pyspark.sql import Row, DataFrame\n",
    "import json\n",
    "\n",
    "from xinghe.spark import *\n",
    "from app.common.json_util import *\n",
    "from xinghe.s3 import *\n",
    "\n",
    "config = {\n",
    "    \"spark_conf_name\": \"spark_4\",\n",
    "    \"skip_success_check\": True,\n",
    "    \"spark.executorEnv.LLM_WEB_KIT_CFG_PATH\": \"/share/xuchao/.llm-web-kit.jsonc\",\n",
    "    \n",
    "}\n",
    "\n",
    "spark = new_spark_session(\"zhangwenwei-math-page-parse\", config)\n",
    "# spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9fb561-22fd-479d-b05c-d4538370a29a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T14:58:34.223468Z",
     "iopub.status.busy": "2025-02-24T14:58:34.223315Z",
     "iopub.status.idle": "2025-02-24T15:07:00.867238Z",
     "shell.execute_reply": "2025-02-24T15:07:00.866177Z",
     "shell.execute_reply.started": "2025-02-24T14:58:34.223451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/24 23:02:54 WARN DataStreamer: Exception for BP-478506872-10.140.92.21-1735280705974:blk_1073801828_61600\n",
      "java.io.EOFException: Unexpected EOF while trying to read response from server\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:521)\n",
      "\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1137)\n",
      "25/02/24 23:02:54 WARN DataStreamer: Error Recovery for BP-478506872-10.140.92.21-1735280705974:blk_1073801828_61600 in pipeline [DatanodeInfoWithStorage[10.140.92.23:9966,DS-bff5f31e-4145-44e5-86bf-aeea81b5e216,DISK], DatanodeInfoWithStorage[10.140.92.160:9966,DS-f9591a1d-0f60-494b-93d1-abb3dfbb4d22,DISK], DatanodeInfoWithStorage[10.140.92.235:9966,DS-f49897f9-2f5a-4a53-9e23-f4d111a03528,DISK]]: datanode 0(DatanodeInfoWithStorage[10.140.92.23:9966,DS-bff5f31e-4145-44e5-86bf-aeea81b5e216,DISK]) is bad.\n",
      "25/02/24 23:05:56 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n"
     ]
    }
   ],
   "source": [
    "input_paths = [\n",
    "    \"s3://web-parse-huawei/renpengli/html-exp/math/v001/\",\n",
    "]\n",
    "input_df = read_any_path(spark, \",\".join(input_paths), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1652f26d-f973-4648-966f-01231bbe5125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T06:42:31.567725Z",
     "iopub.status.busy": "2025-02-24T06:42:31.567557Z",
     "iopub.status.idle": "2025-02-24T06:48:00.987792Z",
     "shell.execute_reply": "2025-02-24T06:48:00.987176Z",
     "shell.execute_reply.started": "2025-02-24T06:42:31.567709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/24 14:44:24 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "38856812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b6e0c-c3cf-4965-8e53-b50582c14fc7",
   "metadata": {},
   "source": [
    "# 先按照最长域名进行一次过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264d5816-4e9a-468a-9ab0-8d4960193c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:07:00.868732Z",
     "iopub.status.busy": "2025-02-24T15:07:00.868522Z",
     "iopub.status.idle": "2025-02-24T15:07:00.874274Z",
     "shell.execute_reply": "2025-02-24T15:07:00.873429Z",
     "shell.execute_reply.started": "2025-02-24T15:07:00.868715Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_fraction = 1.0\n",
    "if sample_fraction==1.0:\n",
    "    df_sample = input_df\n",
    "else:\n",
    "    df_sample = input_df.sample(fraction=sample_fraction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e36fa-2ac6-4b85-87db-128242c8db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ed207-c1cf-40a6-ada9-e28044492095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566529fa-3010-464d-9aae-38f138aca7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:07:00.875518Z",
     "iopub.status.busy": "2025-02-24T15:07:00.875154Z",
     "iopub.status.idle": "2025-02-24T15:08:42.676691Z",
     "shell.execute_reply": "2025-02-24T15:08:42.675944Z",
     "shell.execute_reply.started": "2025-02-24T15:07:00.875497Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_rdd = df_sample.rdd.repartition(6000).map(lambda x: Row(**json.loads(x.value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062b58d-f52e-43bf-b4e6-6705db026ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_rdd.take(1)[0]\n",
    "sample.asDict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c617c8-d401-43d2-b0c2-715cf9ff57e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:08:42.677960Z",
     "iopub.status.busy": "2025-02-24T15:08:42.677569Z",
     "iopub.status.idle": "2025-02-24T15:08:42.685102Z",
     "shell.execute_reply": "2025-02-24T15:08:42.684582Z",
     "shell.execute_reply.started": "2025-02-24T15:08:42.677940Z"
    }
   },
   "outputs": [],
   "source": [
    "# 过滤掉不需要的字段\n",
    "page_layout_type_map = {\n",
    "    \"论坛\":\"forum\",\n",
    "    \"个人网站\":\"article\",\n",
    "    \"百科\":\"article\",\n",
    "    \"知乎\":\"forum\",\n",
    "    \"官方网站\":\"forum\",\n",
    "    \"博客\":\"article\",\n",
    "    \"\":\"article\"\n",
    "}\n",
    "\n",
    "wanted_domain_list = [\n",
    "    \"https://math.stackexchange.com/\",\n",
    "    \"https://mathoverflow.net/\",\n",
    "    \"https://mathhelpforum.com/\",\n",
    "    \"https://stats.stackexchange.com/\",\n",
    "    \"https://clay6.com/\",\n",
    "    \"https://encyclopediaofmath.org/\",\n",
    "    \"https://mathforums.com/\",\n",
    "    \"https://www.randomservices.org/random/index.html\",\n",
    "    \"https://www.mathisfunforum.com/\",\n",
    "    \"https://www.physicsforums.com/\"\n",
    "]\n",
    "\n",
    "wanted_domain_list = [\n",
    "    \"https://physicshelpforum.com/\",\n",
    "    \"https://physics.stackexchange.com/\",\n",
    "    \"https://mathematica.stackexchange.com/\",\n",
    "    \"https://www.bananaspace.org/\",\n",
    "    \"https://www.mathorg.cn/\",\n",
    "    \"https://www.cnblogs.com/zhangzujin\",\n",
    "    \"https://ccjou.wordpress.com/\",\n",
    "    \"https://chaoli.club/\",\n",
    "    \"https://sketchesoftopology.wordpress.com/\",\n",
    "    \"https://projecteuler.net/\",\n",
    "    \"https://unapologetic.wordpress.com/\",\n",
    "    \"https://zhuanlan.zhihu.com/c_69585507\",\n",
    "    \"https://www.tapatalk.com/groups/integralsandseries/\",\n",
    "    \"https://mathshistory.st-andrews.ac.uk/\",\n",
    "    \"https://www.mathsisfun.com/index.htm\",\n",
    "    \"https://frankliou.wordpress.com/\",\n",
    "    \"https://calcgospel.top/\",\n",
    "    \"https://betterexplained.com/\",\n",
    "    \"http://www.matrix67.com/blog/\",\n",
    "    \"https://www.freemathhelp.com/forum/\"\n",
    "]\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "wanted_domain = []\n",
    "for url in wanted_domain_list:\n",
    "    long_domain = urlparse(url).netloc\n",
    "    wanted_domain.append(long_domain)\n",
    "\n",
    "\n",
    "formated_rdd = sample_rdd.filter(lambda x: x.domain in wanted_domain).map(lambda x: Row(track_id=x.track_id, url=x.url, html=x.html, page_layout_type=page_layout_type_map.get(x.site_type, \"article\"), domain=x.domain, dataset_name='math', data_source_category='HTML', meta_info=x.remark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a222dff-dfa6-4970-adb5-235cf4334556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:08:42.687026Z",
     "iopub.status.busy": "2025-02-24T15:08:42.686638Z",
     "iopub.status.idle": "2025-02-24T15:15:11.200055Z",
     "shell.execute_reply": "2025-02-24T15:15:11.199423Z",
     "shell.execute_reply.started": "2025-02-24T15:08:42.687008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "9534344"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formated_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e27eab0-d523-4c59-b82c-86579a4ecae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:11.201027Z",
     "iopub.status.busy": "2025-02-24T15:15:11.200861Z",
     "iopub.status.idle": "2025-02-24T15:15:11.222859Z",
     "shell.execute_reply": "2025-02-24T15:15:11.222194Z",
     "shell.execute_reply.started": "2025-02-24T15:15:11.201010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[14] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formated_rdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4acd5e-e750-42fd-97f8-f01f2bdd1385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 测试一下错误原因，可跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6363d2-21f7-42cd-af25-9f504d486aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from llm_web_kit.input.datajson import DataJson\n",
    "from llm_web_kit.extractor.extractor_chain import ExtractSimpleFactory\n",
    "from func_timeout import FunctionTimedOut, func_timeout\n",
    "\n",
    "os.environ[\"LLM_WEB_KIT_CFG_PATH\"] = \"/share/xuchao/.llm-web-kit.jsonc\"\n",
    "\n",
    "item = formated_rdd.take(1)[0]\n",
    "d = item.asDict()\n",
    "d.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8e429-57b5-4a42-b7c2-e0a19552b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = DataJson(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7f5f1-d082-43b8-9ae4-55052e4d1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_chain = ExtractSimpleFactory.create('/share/xuchao/notebooks/math专项/math-cc.jsonc')\n",
    "\n",
    "\n",
    "r: DataJson = func_timeout(10, extractor_chain.extract, args=(input_data,))\n",
    "# r = extractor_chain.extract(input_data)\n",
    "r.to_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef4157-1298-4da8-b1b0-c0cb01fb5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['content_list'].length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30cec5e-a129-43c8-942b-366a00d03a7a",
   "metadata": {},
   "source": [
    "## 解析函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68eeec6d-7746-4082-b33c-0a813141c5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:11.223957Z",
     "iopub.status.busy": "2025-02-24T15:15:11.223548Z",
     "iopub.status.idle": "2025-02-24T15:15:11.544367Z",
     "shell.execute_reply": "2025-02-24T15:15:11.543749Z",
     "shell.execute_reply.started": "2025-02-24T15:15:11.223939Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from llm_web_kit.input.datajson import DataJson\n",
    "from llm_web_kit.extractor.extractor_chain import ExtractSimpleFactory\n",
    "from func_timeout import FunctionTimedOut, func_timeout\n",
    "\n",
    "os.environ[\"LLM_WEB_KIT_CFG_PATH\"] = \"/share/xuchao/.llm-web-kit.jsonc\"\n",
    "\n",
    "def extract_data(_iter):\n",
    "    from loguru import logger\n",
    "    extractor_chain = ExtractSimpleFactory.create('/share/xuchao/notebooks/math专项/math-cc.jsonc')\n",
    "    timeout_seconds = 10\n",
    "    # 为每个分区创建唯一的错误日志文件\n",
    "    # partition_id = str(uuid.uuid4())\n",
    "    # current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # error_log_path = f\"s3://xyz-llm-users/xyz-users/yujia/CC-MAIN-2024-33/output/v002/error_logs/{current_time}_{partition_id}.json\"\n",
    "    # s3_doc_writer = S3DocWriter(path=error_log_path)\n",
    "\n",
    "    for row in _iter:\n",
    "        d = row.asDict()\n",
    "        try:\n",
    "            input_data = DataJson(d)\n",
    "            data_e: DataJson = func_timeout(timeout_seconds, extractor_chain.extract, args=(input_data,))\n",
    "            \n",
    "            #data_e: DataJson = extractor_chain.extract(input_data)\n",
    "            yield Row(**data_e.to_dict())\n",
    "        except FunctionTimedOut as e1:\n",
    "            d['__error'] = {\n",
    "                \"error_type\":\"TIMEOUT\",\n",
    "                \"error_message\": \"extract function timeout\",\n",
    "                \"traceback\":\"TIMEOUT\"\n",
    "            }\n",
    "            yield Row(**d)\n",
    "        except Exception as e:\n",
    "            # 记录更详细的错误信息\n",
    "            error_info = {\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error_message\": str(e),\n",
    "                \"traceback\": traceback.format_exc(),\n",
    "            }\n",
    "            logger.error(error_info)\n",
    "            # s3_doc_writer.write(error_info)\n",
    "            d['__error'] = error_info\n",
    "            yield Row(**d)\n",
    "\n",
    "    # 确保在分区处理完成后刷新并关闭文件\n",
    "    # try:\n",
    "    #     s3_doc_writer.flush()\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error flushing error logs: {str(e)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c64691a-9fa0-48a6-9240-3e32ea537907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:11.545314Z",
     "iopub.status.busy": "2025-02-24T15:15:11.545029Z",
     "iopub.status.idle": "2025-02-24T15:15:11.548014Z",
     "shell.execute_reply": "2025-02-24T15:15:11.547537Z",
     "shell.execute_reply.started": "2025-02-24T15:15:11.545297Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df = formated_rdd.mapPartitions(extract_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca097c1-aec5-45e8-aa7d-9775d65a15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b0f71-fc92-4bde-bbcd-ff0803383980",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_result = result_df.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d4968-7f8e-4845-9686-ef3f9eabf8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_result.asDict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8b1af4-603e-4d38-a4c2-4890873b439f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:11.548743Z",
     "iopub.status.busy": "2025-02-24T15:15:11.548586Z",
     "iopub.status.idle": "2025-02-24T15:15:15.764105Z",
     "shell.execute_reply": "2025-02-24T15:15:15.763529Z",
     "shell.execute_reply.started": "2025-02-24T15:15:11.548729Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = result_df.take(1)[0]\n",
    "type(m.content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "401e2a67-00d9-47ae-a94c-97238ea1d051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:15.764963Z",
     "iopub.status.busy": "2025-02-24T15:15:15.764803Z",
     "iopub.status.idle": "2025-02-24T15:15:17.361048Z",
     "shell.execute_reply": "2025-02-24T15:15:17.360418Z",
     "shell.execute_reply.started": "2025-02-24T15:15:15.764947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r2 = result_df.filter(lambda x:\"__error\" not in x)\n",
    "m = df_r2.take(1)[0]\n",
    "type(m.content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50099802-b2ac-4080-85ed-85d5702528d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:17.362149Z",
     "iopub.status.busy": "2025-02-24T15:15:17.361794Z",
     "iopub.status.idle": "2025-02-24T15:15:17.365571Z",
     "shell.execute_reply": "2025-02-24T15:15:17.364927Z",
     "shell.execute_reply.started": "2025-02-24T15:15:17.362129Z"
    }
   },
   "outputs": [],
   "source": [
    "df_r1 = result_df.filter(lambda x:\"__error\" in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdc5ee52-82dc-44b9-95f4-89169acb8c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:17.366271Z",
     "iopub.status.busy": "2025-02-24T15:15:17.366130Z",
     "iopub.status.idle": "2025-02-24T15:15:58.042486Z",
     "shell.execute_reply": "2025-02-24T15:15:58.041936Z",
     "shell.execute_reply.started": "2025-02-24T15:15:17.366258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "llm_web_kit.input.datajson.ContentList"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = df_r1.take(1)[0]\n",
    "type(m.content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3400b2-16f1-48c5-b332-53aeb1021cf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:15:58.043269Z",
     "iopub.status.busy": "2025-02-24T15:15:58.043113Z",
     "iopub.status.idle": "2025-02-24T15:22:33.645856Z",
     "shell.execute_reply": "2025-02-24T15:22:33.645244Z",
     "shell.execute_reply.started": "2025-02-24T15:15:58.043253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "1673"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe5b8e91-c7a3-45fd-b3a5-22830c0f513b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:22:33.646729Z",
     "iopub.status.busy": "2025-02-24T15:22:33.646542Z",
     "iopub.status.idle": "2025-02-24T15:22:33.661592Z",
     "shell.execute_reply": "2025-02-24T15:22:33.660926Z",
     "shell.execute_reply.started": "2025-02-24T15:22:33.646712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[19] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/24 23:29:48 WARN DataStreamer: Exception for BP-478506872-10.140.92.21-1735280705974:blk_1073801828_61602\n",
      "java.io.EOFException: Unexpected EOF while trying to read response from server\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:521)\n",
      "\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1137)\n",
      "25/02/24 23:29:48 WARN DataStreamer: Error Recovery for BP-478506872-10.140.92.21-1735280705974:blk_1073801828_61602 in pipeline [DatanodeInfoWithStorage[10.140.92.160:9966,DS-f9591a1d-0f60-494b-93d1-abb3dfbb4d22,DISK], DatanodeInfoWithStorage[10.140.92.235:9966,DS-f49897f9-2f5a-4a53-9e23-f4d111a03528,DISK], DatanodeInfoWithStorage[10.140.92.117:9966,DS-f2830abd-7fce-4b3d-b459-be2974a0c524,DISK]]: datanode 0(DatanodeInfoWithStorage[10.140.92.160:9966,DS-f9591a1d-0f60-494b-93d1-abb3dfbb4d22,DISK]) is bad.\n"
     ]
    }
   ],
   "source": [
    "df_r1.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc260f-1cfd-405e-9b76-9133fb19e138",
   "metadata": {},
   "source": [
    "## 保存content_list数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981bddd1-1c6f-44be-b1be-68edf11023c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc_main3_path = \"s3://web-parse-hw60p/xuchao/CC/math-zhangwenwei/v004/\"\n",
    "config['skip_output_check'] = True\n",
    "write_any_path(result_df.filter(lambda x:\"__error\" not in x).map(lambda x: Row(value=json.dumps(x.asDict()))).toDF(), cc_main3_path, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e388864-a540-40c2-9ecb-342edf1fa502",
   "metadata": {},
   "source": [
    "## 保存拼装的MD数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d12c18-e428-4a2e-9b3f-e35a4119a7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llm_web_kit.input.datajson import DataJson\n",
    "\n",
    "def make_content_md(row):\n",
    "    d = row.asDict()\n",
    "    try:\n",
    "        d['md_content'] = DataJson(d).get_content_list().to_nlp_md()\n",
    "    except AttributeError as e:\n",
    "        d['__error'] = str(e)\n",
    "        \n",
    "    del d['content_list']\n",
    "    return Row(**d)\n",
    "    \n",
    "\n",
    "config['skip_output_check'] = True\n",
    "\n",
    "df_r1 = result_df.filter(lambda x:\"__error\" not in x).map(make_content_md)\n",
    "\n",
    "df_r_succ = df_r1.filter(lambda x:\"__error\" not in x).map(lambda x: Row(value=json.dumps(x.asDict())))\n",
    "df_r_err = df_r1.filter(lambda x:\"__error\"  in x).map(lambda x: Row(value=json.dumps(x.asDict())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc1e8f-847d-4af1-91ee-6369fdb9031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_succ.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbae09-c6f2-4039-9350-c34033bdc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_err.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45bbbb-9df3-4c90-b414-d748fd584bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_main4_path = \"s3://web-parse-hw60p/xuchao/CC/math-zhangwenwei/v004-md-1/\"\n",
    "write_any_path(df_r_succ.toDF(), cc_main4_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec7a5ff-e51c-4348-9ef2-dfb5670f85a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T13:08:03.595422Z",
     "iopub.status.busy": "2025-02-24T13:08:03.595039Z",
     "iopub.status.idle": "2025-02-24T13:08:03.598270Z",
     "shell.execute_reply": "2025-02-24T13:08:03.597777Z",
     "shell.execute_reply.started": "2025-02-24T13:08:03.595402Z"
    }
   },
   "outputs": [],
   "source": [
    "err_path = \"s3://web-parse-hw60p/xuchao/CC/math-zhangwenwei/v007-md-error/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7a4a4-d41e-4fa1-b630-5ec509d60abe",
   "metadata": {},
   "source": [
    "### 把拼装MD时候发生的错误保存下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da109c6f-49e9-4108-b362-97f19f057853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T13:34:09.074049Z",
     "iopub.status.busy": "2025-02-24T13:34:09.073669Z",
     "iopub.status.idle": "2025-02-24T13:44:35.155348Z",
     "shell.execute_reply": "2025-02-24T13:44:35.154626Z",
     "shell.execute_reply.started": "2025-02-24T13:34:09.074029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rows': 1675,\n",
       " 'bytes': {'sum': 332630581,\n",
       "  'min': 11686,\n",
       "  'max': 1099354,\n",
       "  'cnt': 1675,\n",
       "  'avg': 198585.421},\n",
       " 'files': 1,\n",
       " 'sub_paths': {}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/24 22:10:45 WARN DataStreamer: Exception for BP-478506872-10.140.92.21-1735280705974:blk_1073801709_61480\n",
      "java.io.EOFException: Unexpected EOF while trying to read response from server\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:521)\n",
      "\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1137)\n",
      "25/02/24 22:10:45 WARN DataStreamer: Error Recovery for BP-478506872-10.140.92.21-1735280705974:blk_1073801709_61480 in pipeline [DatanodeInfoWithStorage[10.140.92.31:9966,DS-73dec8e7-b5fd-40dd-907b-e698e6eb61fd,DISK], DatanodeInfoWithStorage[10.140.92.196:9966,DS-4425134a-c7dd-4887-9ad0-20583445d5ac,DISK], DatanodeInfoWithStorage[10.140.92.251:9966,DS-645c224a-73fb-4301-b2f1-e4a48baacf6f,DISK]]: datanode 0(DatanodeInfoWithStorage[10.140.92.31:9966,DS-73dec8e7-b5fd-40dd-907b-e698e6eb61fd,DISK]) is bad.\n"
     ]
    }
   ],
   "source": [
    "def datajson2str(r):\n",
    "    d = r.asDict()\n",
    "    d['content_list'] = d['content_list']._get_data()\n",
    "    d = DataJson(d)\n",
    "    dict_ = d.to_json()\n",
    "    return Row(value=dict_)\n",
    "\n",
    "df_err_1 = df_r1.map(datajson2str)\n",
    "write_any_path(df_err_1.repartition(1).toDF(), err_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24dad9b2-7d53-42b1-ba1b-a0214eb92719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T14:42:43.472368Z",
     "iopub.status.busy": "2025-02-24T14:42:43.471891Z",
     "iopub.status.idle": "2025-02-24T14:43:26.348347Z",
     "shell.execute_reply": "2025-02-24T14:43:26.347787Z",
     "shell.execute_reply.started": "2025-02-24T14:42:43.472347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "llm_web_kit.input.datajson.ContentList"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = df_r1.take(1)[0]\n",
    "type(m.content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471f2e46-e341-4700-959b-057480c3228f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T13:29:36.034732Z",
     "iopub.status.busy": "2025-02-24T13:29:36.034371Z",
     "iopub.status.idle": "2025-02-24T13:30:16.555558Z",
     "shell.execute_reply": "2025-02-24T13:30:16.554978Z",
     "shell.execute_reply.started": "2025-02-24T13:29:36.034712Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['track_id', 'url', 'html', 'page_layout_type', 'domain', 'dataset_name', 'data_source_category', 'meta_info', 'content_list', '__error'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = df_r1.take(1)[0]\n",
    "r.asDict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e891ef58-a898-4672-a38f-2b3ebabdbf6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T13:30:25.152666Z",
     "iopub.status.busy": "2025-02-24T13:30:25.152302Z",
     "iopub.status.idle": "2025-02-24T13:30:25.156578Z",
     "shell.execute_reply": "2025-02-24T13:30:25.156089Z",
     "shell.execute_reply.started": "2025-02-24T13:30:25.152646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llm_web_kit.input.datajson.ContentList at 0x7fe54817e260>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.asDict()['content_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048dc50d-b91e-4611-b6c9-bd8eb728b2e9",
   "metadata": {},
   "source": [
    "## check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e5718-a6ae-43e9-854a-83eecf27c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat(\"s3://web-parse-hw60p/xuchao/CC/math-zhangwenwei/v001/part-67b6a61edd6e-000003.jsonl\")\n",
    "import inspect\n",
    "\n",
    "\n",
    "# 假设some_module中有一个函数叫做some_function\n",
    "source_code = inspect.getsource(cat)\n",
    "print(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7d1f4-e8be-4b51-91b3-3ba7e015b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mycat(path, limit=1, show_loc=False):\n",
    "    if \"?bytes=\" in path:\n",
    "        row = read_s3_row(path)\n",
    "        if row is not None:\n",
    "            if show_loc:\n",
    "                #print(row.loc)\n",
    "                pass\n",
    "            #json_print(row)\n",
    "            return json.loads(row.value)\n",
    "    for row in read_s3_rows(path, use_stream=True, limit=limit):\n",
    "        if show_loc:\n",
    "            #print(row.loc)\n",
    "            pass\n",
    "        return json.loads(row.value)\n",
    "\n",
    "line  = mycat(\"s3://web-parse-hw60p/xuchao/CC/math-zhangwenwei/v001/part-67b6a61edd6e-000003.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444430da-4a38-4a89-a0b6-1eb3c38067bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = line['url']\n",
    "cl = line['content_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2815b-b359-45b8-a628-6949be26f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "line.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b126b9-db37-4454-a171-f4e46999c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4b791-e56b-448f-94d8-a12f7d34b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_web_kit.input.datajson import DataJson\n",
    "dataj = DataJson(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0e499-de6b-4ebe-9db3-bfd1095e2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dataj.get_content_list().to_nlp_md()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda2fad-3f9d-45b3-b2f3-22a265c07770",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48725947-90da-4185-a004-1ba5453d136c",
   "metadata": {},
   "source": [
    "# 分析错误数据原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90ddad-34a0-4ed1-9c66-fafd9e906e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df  = read_any_path(spark, err_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598978c5-ff8e-4b25-9adc-484bca627efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df = err_df.rdd.map(lambda x: Row(**json.loads(x.value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337fdb5-903c-4b44-8fc3-1c2e19eeae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df.toDF().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e9cf7-f846-463d-9fdd-59d34f72752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df.toDF().select(\"__error\").distinct().show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7917414-228d-4dfc-82f7-c0caab661a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from llm_web_kit.input.datajson import DataJson\n",
    "from llm_web_kit.extractor.extractor_chain import ExtractSimpleFactory\n",
    "from func_timeout import FunctionTimedOut, func_timeout\n",
    "\n",
    "os.environ[\"LLM_WEB_KIT_CFG_PATH\"] = \"\n",
    "\"\n",
    "extractor_chain = ExtractSimpleFactory.create('/share/xuchao/notebooks/math专项/math-cc.jsonc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0b119-fd7d-429d-ba06-2446cadbd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = err_df.collect()\n",
    "for row in rows:\n",
    "    row = err_df.take(1)[0].asDict()\n",
    "    data = DataJson(row)\n",
    "    extractor_chain.extract(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d5a79-a5c9-46b7-bcf7-6cdb8e2caff7",
   "metadata": {},
   "source": [
    "## 分析未保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "429610f2-be87-473b-98a5-2ef2736ba8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T10:10:03.686854Z",
     "iopub.status.busy": "2025-02-24T10:10:03.686350Z",
     "iopub.status.idle": "2025-02-24T10:10:03.765498Z",
     "shell.execute_reply": "2025-02-24T10:10:03.764885Z",
     "shell.execute_reply.started": "2025-02-24T10:10:03.686833Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_r1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2297\u001b[0m, in \u001b[0;36mRDD.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;124;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2272\u001b[0m, in \u001b[0;36mRDD.sum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[NumberOrArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOrArray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;124;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2254\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;124;03m    6.0\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\n\u001b[1;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2025\u001b[0m, in \u001b[0;36mRDD.fold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1814\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "df_r1.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0fae989-198c-4266-a0f5-09b6de399fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T08:45:26.587354Z",
     "iopub.status.busy": "2025-02-24T08:45:26.586830Z",
     "iopub.status.idle": "2025-02-24T08:45:26.591323Z",
     "shell.execute_reply": "2025-02-24T08:45:26.590755Z",
     "shell.execute_reply.started": "2025-02-24T08:45:26.587332Z"
    }
   },
   "outputs": [],
   "source": [
    "def trans(row):\n",
    "    d = row.asDict()\n",
    "    d['__error'] = json.dumps(d['__error'], ensure_ascii=False)\n",
    "    return Row(**d)\n",
    "\n",
    "df_err = df_r1.map(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95fe3339-66f6-4aeb-8a57-3c09114ed04a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T10:09:51.961275Z",
     "iopub.status.busy": "2025-02-24T10:09:51.960769Z",
     "iopub.status.idle": "2025-02-24T10:09:52.034124Z",
     "shell.execute_reply": "2025-02-24T10:09:52.033515Z",
     "shell.execute_reply.started": "2025-02-24T10:09:51.961254Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_err\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2297\u001b[0m, in \u001b[0;36mRDD.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;124;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2272\u001b[0m, in \u001b[0;36mRDD.sum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[NumberOrArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOrArray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;124;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2254\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;124;03m    6.0\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\n\u001b[1;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2025\u001b[0m, in \u001b[0;36mRDD.fold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1814\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "df_err.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4171209-9ffb-4cca-99b9-09f81fa52d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T08:45:30.911966Z",
     "iopub.status.busy": "2025-02-24T08:45:30.911397Z",
     "iopub.status.idle": "2025-02-24T08:45:30.998849Z",
     "shell.execute_reply": "2025-02-24T08:45:30.998171Z",
     "shell.execute_reply.started": "2025-02-24T08:45:30.911943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"error_type\": \"AttributeError\", \"error_message\": \"\\'NoneType\\' object has no attribute \\'strip\\'\", \"traceback\": \"Traceback (most recent call last):\\\\n  File \\\\\"/tmp/ipykernel_1717/2920365159.py\\\\\", line 25, in extract_data\\\\n  File \\\\\"/share/xuchao/.conda/envs/webkitdev/lib/python3.10/site-packages/func_timeout/dafunc.py\\\\\", line 108, in func_timeout\\\\n    raise_exception(exception)\\\\n  File \\\\\"/share/xuchao/.conda/envs/webkitdev/lib/python3.10/site-packages/func_timeout/py3_raise.py\\\\\", line 7, in raise_exception\\\\n    raise exception[0] from None\\\\n  File \\\\\"/share/xuchao/llm-webkit-mirror/llm_web_kit/extractor/extractor_chain.py\\\\\", line 51, in extract\\\\n    data = ext.extract(data)\\\\n  File \\\\\"/share/xuchao/llm-webkit-mirror/llm_web_kit/extractor/extractor.py\\\\\", line 34, in extract\\\\n    return self._do_extract(data_json)\\\\n  File \\\\\"/share/xuchao/llm-webkit-mirror/llm_web_kit/extractor/html/extractor.py\\\\\", line 101, in _do_extract\\\\n    content_list:ContentList = self._export_to_content_list(base_url, parsed_html, raw_html)\\\\n  File \\\\\"/share/xuchao/llm-webkit-mirror/llm_web_kit/extractor/html/extractor.py\\\\\", line 265, in _export_to_content_list\\\\n    node = parser.to_content_list_node(base_url, ccnode_html, raw_html)\\\\n  File \\\\\"/share/xuchao/llm-webkit-mirror/llm_web_kit/extractor/html/recognizer/ccmath.py\\\\\", line 80, in to_content_list_node\\\\n    math_content = cm.wrap_math_md(math_content)\\\\n  File \\\\\"/share/xuchao/llm-webkit-mirror/llm_web_kit/extractor/html/recognizer/cc_math/common.py\\\\\", line 147, in wrap_math_md\\\\n    s = s.strip()\\\\nAttributeError: \\'NoneType\\' object has no attribute \\'strip\\'\\\\n\"}'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = df_err.take(1)[0]\n",
    "r.asDict()['__error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb10977e-8947-484d-9e88-0b8e0b9bbd46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T10:09:36.232634Z",
     "iopub.status.busy": "2025-02-24T10:09:36.232139Z",
     "iopub.status.idle": "2025-02-24T10:09:36.749243Z",
     "shell.execute_reply": "2025-02-24T10:09:36.748645Z",
     "shell.execute_reply.started": "2025-02-24T10:09:36.232604Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m only_err \u001b[38;5;241m=\u001b[39m df_err\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: Row(error\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39masDict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__error\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m----> 2\u001b[0m \u001b[43monly_err\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcc_math\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2297\u001b[0m, in \u001b[0;36mRDD.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;124;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2272\u001b[0m, in \u001b[0;36mRDD.sum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[NumberOrArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOrArray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;124;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2254\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;124;03m    6.0\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\n\u001b[1;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2025\u001b[0m, in \u001b[0;36mRDD.fold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1814\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "only_err = df_err.map(lambda x: Row(error=x.asDict()['__error']))\n",
    "only_err.filter(lambda x: \"cc_math\" in x.asDict()['error']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af5a83a8-9615-446a-869c-4f6726f52046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T10:08:34.822947Z",
     "iopub.status.busy": "2025-02-24T10:08:34.822753Z",
     "iopub.status.idle": "2025-02-24T10:08:34.938384Z",
     "shell.execute_reply": "2025-02-24T10:08:34.937498Z",
     "shell.execute_reply.started": "2025-02-24T10:08:34.822930Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m img_err \u001b[38;5;241m=\u001b[39m only_err\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcc_math\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39masDict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvg_to_base64\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39masDict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mimg_err\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2297\u001b[0m, in \u001b[0;36mRDD.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;124;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2272\u001b[0m, in \u001b[0;36mRDD.sum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[NumberOrArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOrArray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;124;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2254\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;124;03m    6.0\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\n\u001b[1;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:2025\u001b[0m, in \u001b[0;36mRDD.fold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1814\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.conda/envs/webkitdev/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "img_err = only_err.filter(lambda x: \"cc_math\" not in x.asDict()['error']).filter(lambda x: \"svg_to_base64\" in x.asDict()['error'])\n",
    "img_err.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmwebkit-dev(py310)",
   "language": "python",
   "name": "python3.10-webkitdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
