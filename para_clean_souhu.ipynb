{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a69d86a-0e19-413c-8c2d-64c8e749065c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:35:43.576682Z",
     "iopub.status.busy": "2025-03-18T02:35:43.576059Z",
     "iopub.status.idle": "2025-03-18T02:35:44.783064Z",
     "shell.execute_reply": "2025-03-18T02:35:44.782461Z",
     "shell.execute_reply.started": "2025-03-18T02:35:43.576655Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "import uuid\n",
    "from functools import partial\n",
    "from typing import Iterable, Dict, Any\n",
    "# create spark session\n",
    "from pyspark.sql import Row, DataFrame\n",
    "from loguru import logger\n",
    "from xinghe.spark import *\n",
    "from app.common.json_util import *\n",
    "\n",
    "from xinghe.s3 import *\n",
    "\n",
    "\n",
    "import os\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "import uuid\n",
    "from functools import partial\n",
    "from typing import Iterable, Dict, Any\n",
    "# create spark session\n",
    "from pyspark.sql import Row, DataFrame\n",
    "from loguru import logger\n",
    "from xinghe.spark import *\n",
    "from app.common.json_util import *\n",
    "\n",
    "from xinghe.s3 import *\n",
    "\n",
    "\n",
    "import uuid\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from llm_web_kit.input.datajson import DataJson\n",
    "from func_timeout import FunctionTimedOut, func_timeout\n",
    "import os\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "import uuid\n",
    "from functools import partial\n",
    "from typing import Iterable, Dict, Any\n",
    "# create spark session\n",
    "from pyspark.sql import Row, DataFrame\n",
    "from loguru import logger\n",
    "from xinghe.spark import *\n",
    "from app.common.json_util import *\n",
    "\n",
    "from xinghe.s3 import *\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "import uuid\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from llm_web_kit.input.datajson import DataJson\n",
    "from func_timeout import FunctionTimedOut, func_timeout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a217b13-0ce3-4e46-9d99-7c9b6acbfb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:35:44.784441Z",
     "iopub.status.busy": "2025-03-18T02:35:44.784240Z",
     "iopub.status.idle": "2025-03-18T02:35:44.830641Z",
     "shell.execute_reply": "2025-03-18T02:35:44.830160Z",
     "shell.execute_reply.started": "2025-03-18T02:35:44.784425Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def transform_row(row, config: dict) -> Row:\n",
    "\n",
    "    \"\"\"根据平台配置转换行数据\"\"\"\n",
    "    mappings = config\n",
    "    from loguru import logger\n",
    "    try:\n",
    "\n",
    "         # 获取已使用的字段名\n",
    "        used_field_names = {\n",
    "            mappings[\"track_id\"],\n",
    "            mappings[\"url\"],\n",
    "            mappings[\"html\"],\n",
    "            mappings[\"layout_field\"],\n",
    "            \"filename\"  # 显式使用的filename字段\n",
    "        }\n",
    "\n",
    "        # 获取原始行的所有字段名\n",
    "        row_field_names = row.__fields__  # 适用于pyspark.sql.Row对象\n",
    "\n",
    "        # 收集未被使用的字段\n",
    "        remaining_fields = [f for f in row_field_names if f not in used_field_names]\n",
    "        print(remaining_fields)\n",
    "        # 构建meta_info字典\n",
    "        meta_info = {\"filename\": getattr(row, \"filename\", \"\")}\n",
    "        for field in remaining_fields:\n",
    "            meta_info[field] = getattr(row, field, None)\n",
    "\n",
    "        d = Row(\n",
    "                track_id=getattr(row, mappings[\"track_id\"],str(uuid.uuid4())),\n",
    "                url=getattr(row, mappings[\"url\"], ''),\n",
    "                html=getattr(row, mappings[\"html\"], ''),\n",
    "                page_layout_type=mappings.get(\"page_layout_type_map\").get(\n",
    "                    getattr(row, mappings[\"layout_field\"], ''),\n",
    "                    \"article\"\n",
    "                ),\n",
    "                domain=extract_domain_info(getattr(row, mappings[\"url\"], ''))['domain'],\n",
    "                dataset_name=mappings[\"dataset_name\"],\n",
    "                data_source_category=mappings[\"data_source_category\"],\n",
    "                meta_info=meta_info\n",
    "            )\n",
    "        return d \n",
    "    except Exception as e:\n",
    "        # 记录更详细的错误信息\n",
    "        error_info = {\n",
    "            \"error_data\":Row(**d),\n",
    "            \"error_type\": type(e).__name__,\n",
    "            \"error_message\": str(e),\n",
    "            \"traceback\": traceback.format_exc(),\n",
    "        }\n",
    "        # s3_doc_writer.write(error_info)\n",
    "        d['__error'] = error_info\n",
    "        logger.error(error_info)\n",
    "        return Row(**d)\n",
    "   \n",
    "\n",
    "\n",
    "def extract_data(partition, broadcast_extractor_config_path):\n",
    "    from llm_web_kit.extractor.extractor_chain import ExtractSimpleFactory\n",
    "    from loguru import logger\n",
    "\n",
    "    extractor_chain = ExtractSimpleFactory.create('/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc')\n",
    "    timeout_seconds = 10\n",
    "    # 为每个分区创建唯一的错误日志文件\n",
    "    # partition_id = str(uuid.uuid4())\n",
    "    # current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # error_log_path = f\"s3://xyz-llm-users/xyz-users/yujia/CC-MAIN-2024-33/output/v002/error_logs/{current_time}_{partition_id}.json\"\n",
    "    # s3_doc_writer = S3DocWriter(path=error_log_path)\n",
    "    for row in partition:\n",
    "        try:\n",
    "\n",
    "            d = row.asDict()\n",
    "            input_data = DataJson(d)\n",
    "            data_e: DataJson = func_timeout(timeout_seconds, extractor_chain.extract, args=(input_data,))\n",
    "            #data_e: DataJson = extractor_chain.extract(input_data)\n",
    "            \n",
    "    \n",
    "            yield Row(**data_e.to_dict())\n",
    "        except FunctionTimedOut as e1:\n",
    "                d['__error'] = {\n",
    "                    \"error_type\":\"TIMEOUT\",\n",
    "                    \"error_message\": \"extract function timeout\",\n",
    "                    \"traceback\":\"TIMEOUT\"\n",
    "                }\n",
    "\n",
    "                yield Row(**d)\n",
    "        except Exception as e:\n",
    "                # 记录更详细的错误信息\n",
    "                error_info = {\n",
    "                    \"error_data\":Row(**d),\n",
    "                    \"error_type\": type(e).__name__,\n",
    "                    \"error_message\": str(e),\n",
    "                    \"traceback\": traceback.format_exc(),\n",
    "                }\n",
    "                logger.error(error_info)\n",
    "                # s3_doc_writer.write(error_info)\n",
    "                d['__error'] = error_info\n",
    "\n",
    "                yield Row(**d)\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_domain_info(url: str) -> dict:\n",
    "    \"\"\"从 URL 中提取完整的域名信息\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    netloc = parsed.netloc\n",
    "    domain_parts = netloc.split(\":\")\n",
    "    domain = domain_parts[0]  # 去除端口号\n",
    "    root_domain = \".\".join(domain.split(\".\")[-2:]) if len(domain.split(\".\")) >= 2 else domain\n",
    "\n",
    "    return {\n",
    "        \"full_url\": url,\n",
    "        \"netloc\": netloc,\n",
    "        \"domain\": domain,\n",
    "        \"root_domain\": root_domain\n",
    "    }\n",
    "        \n",
    "def handle_error(row: Dict, error: Exception) -> Dict:\n",
    "    \"\"\"统一错误处理\"\"\"\n",
    "    row_dict = row.asDict()\n",
    "    return {\n",
    "     ** row,\n",
    "    \"__error\": {\n",
    "        \"type\": type(error).__name__,\n",
    "        \"message\": str(error),\n",
    "        \"traceback\": traceback.format_exc()\n",
    "    }\n",
    "    }\n",
    "\n",
    "    \n",
    "def extract_platform_from_s3_path(s3_path: str) -> str:\n",
    "    \"\"\"\n",
    "    从 S3 路径中提取平台名称（存储桶后的第一个目录）\n",
    "    \n",
    "    示例输入: \n",
    "    - \"s3://private-cooperate-data/zh-web-baijiahao/20241218_p1/\"\n",
    "    输出: \"zh-web-baijiahao\"\n",
    "    \n",
    "    - \"s3://private-cooperate-data/DouBan/\"\n",
    "    输出: \"DouBan\"\n",
    "    \"\"\"\n",
    "    # 分割路径并过滤空字符串\n",
    "    parts = [p for p in s3_path.split(\"/\") if p.strip() != \"\"]\n",
    "    \n",
    "    # 验证路径格式\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"无效的 S3 路径格式: {s3_path}\")\n",
    "    \n",
    "    # 平台名称是存储桶后的第一个目录\n",
    "    \n",
    "    return parts[2]\n",
    "# 定义判断是否为纯文本\n",
    "def is_plain_text(row):\n",
    "    html = row.get(\"html\",\"\")\n",
    "    return not re.search(r'<[^>]+>', html)\n",
    "    \n",
    "# 定义判断content_list是否为空\n",
    "def is_empty_content_list(row):\n",
    "    content_list = row.get(\"content_list\",\"\")\n",
    "    tag =False\n",
    "    for i in content_list:\n",
    "        if len(i) == 0:\n",
    "            tag = True\n",
    "    return tag\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, MapType, StringType\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_text_paragraphs(row):\n",
    "    # 按换行符分割段落，过滤空行\n",
    "    html_content = row.get(\"html\", \"\")\n",
    "    paragraphs = []\n",
    "    tmp_dict = {}\n",
    "    for para in html_content.split('\\n'):\n",
    "        if para.strip():\n",
    "            paragraphs.append({\"c\": para.strip(), \"t\": \"text\"})\n",
    "        \n",
    "    tmp_dict = {\n",
    "            \"type\": \"paragraph\",\n",
    "            \"bbox\": None,\n",
    "            \"raw_content\": None,\n",
    "            \"content\": paragraphs\n",
    "  \n",
    "        }      \n",
    "    # 添加/更新content_list字段\n",
    "    row[\"content_list\"] = [[tmp_dict]]\n",
    "    \n",
    "    # 重建Row对象保留所有原始字段\n",
    "    return row\n",
    "   \n",
    "  \n",
    "import re,regex\n",
    "from typing import List, Dict\n",
    "\n",
    "def is_empty_content(text: str) -> bool:\n",
    "    \"\"\"检查文本是否为空或仅包含空白字符\"\"\"\n",
    "    \n",
    "    return not (text or \"\").strip()\n",
    "\n",
    "def has_excessive_whitespace(text: str) -> bool:\n",
    "    \"\"\"检测过多空格或换行\"\"\"\n",
    "    # 换行符占比超过25%\n",
    "    total_chars = len(text)\n",
    "    if total_chars == 0:\n",
    "        return True\n",
    "    newline_ratio = text.count('\\n') / total_chars\n",
    "    if newline_ratio > 0.25:\n",
    "        return True\n",
    "    \n",
    "    # 连续空格超过500个或连续换行超过8个\n",
    "    if ' ' * 500 in text or '\\n' * 8 in text:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "line_breaks_re = r\"[\\n\\v\\f\\r\\x85\\u2028\\u2029]\"\n",
    "visible_spaces_re = r\"[\\x20\\xa0\\u2000-\\u200a\\u202f\\u205f\\u3000]\"\n",
    "invisible_spaces_re = r\"[\\u200b-\\u200d\\u2060\\ufeff]\"\n",
    "invisible_chars_re = r\"[\\xad\\ufffc\\u2061-\\u2063]\"\n",
    "other_controls_re = r\"[\\x00-\\x08\\x0e-\\x1f\\x7f-\\x84\\x86-\\x9f]\"\n",
    "direction_controls_re = r\"[\\u061c\\u200e\\u200f\\u202a-\\u202e\\u2066-\\u2069]\"\n",
    "head_view_invisible_spaces_re = r\"^[\\x20\\xa0\\u2000-\\u200a\\u202f\\u205f\\u3000 ]\"\n",
    "private_use_area_pattern = (\n",
    "    r\"[\\uE000-\\uF8FF]\"  # BMP 私有使用区\n",
    "    r\"|[\\U000F0000-\\U000FFFFD]\"  # 辅助平面 A 私有使用区\n",
    "    r\"|[\\U00100000-\\U0010FFFD]\"  # 辅助平面 B 私有使用区\n",
    ")\n",
    "ar_invisible_spaces_re = r\"[\\u2060\\ufeff]\"\n",
    "ar_direction_controls_re = r\"[\\u061c\\u202c\\u2066-\\u2069]\"\n",
    "others = r\"[\\u2063\\x00-\\x1F\\x7F-\\x9F�\\u200B-\\u200D\\uFEFF\\u206a\\u206e\\u206f\\u00AD\\u200c\\xa0\\u3000\\u2003\\u2002\\u200e\\u00A0\\u200e\\u25A1\\xa0]|&nbsp|\\\\? :|xa0|&ldquo;|&rdquo;|&rdquo|�|□|&amp|&lt|&gt\"\n",
    "\n",
    "def clean_special_whitespace(s):\n",
    "    if s is None:\n",
    "        return True\n",
    "    s = str(s)\n",
    "    s = re.sub(line_breaks_re, \"\\n\", s)\n",
    "    s = re.sub(visible_spaces_re, \" \", s)\n",
    "    s = re.sub(head_view_invisible_spaces_re, \"\", s)\n",
    "    s = re.sub(invisible_spaces_re, \"\", s)\n",
    "    s = re.sub(direction_controls_re, \"\", s)\n",
    "    s = re.sub(invisible_chars_re, \"\", s)\n",
    "    s = re.sub(other_controls_re, \"\", s)\n",
    "    s = re.sub(private_use_area_pattern, \"\", s)\n",
    "    s = re.sub(others,\"\",s,flags=re.UNICODE)\n",
    "    s = regex.sub(r'\\p{Z}+', ' ', s, flags=regex.UNICODE)\n",
    "    # 匹配任意数量的指定空白字符（包括常规空格、\\u2005、\\u200c等）\n",
    "    return s\n",
    "\n",
    "\n",
    "def clean_html_tag(s):\n",
    "    \"\"\"处理 QUALITY_BAD_EFFECTIVENESS 类型数据质量问题\"\"\"\n",
    "    # 模式选择：清理内容 或 严格过滤\n",
    "    PROCESS_MODE = \"clean\"  # 可配置为 \"filter\" 进行严格过滤\n",
    "    \n",
    "    \n",
    "    # 检测到 HTML 标签时才处理\n",
    "    if bool(re.search(r'<[^>]+>', s)):\n",
    "        if PROCESS_MODE == \"clean\":\n",
    "            \"\"\"清理 HTML 标签，保留文本内容\"\"\"\n",
    "            s = re.sub(r'<\\/?[a-z][^>]*>', '', s, flags=re.IGNORECASE)\n",
    "\n",
    "    return  s\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def is_url(text: str) -> bool:\n",
    "    \"\"\"判断文本是否为URL\"\"\"\n",
    "    url_pattern = re.compile(\n",
    "        r'^(?:http|ftp)s?://'  # 匹配http/https/ftp\n",
    "        r'(?:\\S+(?::\\S*)?@)?'  # 用户名密码\n",
    "        r'(?:\\d{1,3}\\.){3}\\d{1,3}'  # IPv4地址\n",
    "        r'|'                     # 或域名\n",
    "        r'(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+[A-Z]{2,6}'  # 域名\n",
    "        r'(?::\\d+)?'            # 端口\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "    return bool(re.match(url_pattern, text))\n",
    "\n",
    "\n",
    "def is_only_url(text: str) -> bool:\n",
    "    \"\"\"判断字符串是否仅包含一个完整URL且无其他内容\"\"\"\n",
    "    # 优化后的正则表达式，支持常见URL格式\n",
    "    url_pattern = re.compile(\n",
    "        r'^'                            # 字符串开始\n",
    "        r'(https?|ftp)://'              # 协议头\n",
    "        r'(?:\\S+(?::\\S*)?@)?'           # 用户名密码（可选）\n",
    "        r'([a-z0-9\\-]+\\.)+[a-z]{2,}'    # 域名部分\n",
    "        r'(?::\\d+)?'                    # 端口号（可选）\n",
    "        r'(?:/[^\\s?#]*)?'               # 路径（可选）\n",
    "        r'(?:\\?[^\\s#]*)?'               # 查询参数（可选）\n",
    "        r'(?:#[^\\s]*)?'                 # 锚点（可选）\n",
    "        r'$',                           # 字符串结束\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    return url_pattern.fullmatch(text.strip()) is not None\n",
    "\n",
    "def is_too_short(text: str) -> bool:\n",
    "    \"\"\"判断文本长度是否过短\"\"\"\n",
    "    return len(text) <= 21\n",
    "\n",
    "def has_abnormal_chars(text: str) -> bool:\n",
    "    \"\"\"检测异常字符（如不可见字符、�）\"\"\"\n",
    "    abnormal_pattern = re.compile(r'[\\x00-\\x1F\\x7F-\\x9F�\\u200B-\\u200d\\uFEFF\\u00AD\\u200c\\xa0\\u3000\\u2003\\u2002\\u200e]')\n",
    "    return bool(abnormal_pattern.search(text))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def clean_repeat_chars(text, max_repeat=3):\n",
    "    \"\"\"\n",
    "    清理无意义重复字符\n",
    "    :param text: 原始文本\n",
    "    :param max_repeat: 允许的最大连续重复次数(中文建议3-5)\n",
    "    :return: 清洗后文本\n",
    "    \"\"\"\n",
    "    # 匹配超过阈值的连续重复字符（支持全角/半角）\n",
    "    pattern = rf\"([\\w\\W])\\1{{{max_repeat},}}\"\n",
    "    \n",
    "    def replace_func(match):\n",
    "        char = match.group(1)\n",
    "        # 保留不超过允许的重复次数\n",
    "        return char * max_repeat\n",
    "    \n",
    "    return re.sub(pattern, replace_func, text)\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "from typing import List, Dict\n",
    "def is_single_url(text: str) -> bool:\n",
    "    \"\"\"严格判断是否为单个URL（修复括号平衡）\"\"\"\n",
    "    cleaned_text = text.strip().strip(\"'\\\">\")\n",
    "    url_pattern = re.compile(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", re.IGNORECASE)\n",
    "    return url_pattern.fullmatch(cleaned_text) is not None\n",
    "  \n",
    "def is_url_only_content(content: str) -> bool:\n",
    "    \"\"\"判断内容是否全部由URL构成（改进分割逻辑）\"\"\"\n",
    "    if not content.strip():\n",
    "        return False\n",
    "    \n",
    "    # 分割策略：仅按空白符（空格、换行等）分割，保留URL内部字符\n",
    "    segments = re.split(r\"\"\"\\n+|[\\s\\'\">]+|'\"\"\", content.strip())\n",
    "    return all(\n",
    "        is_single_url(segment)\n",
    "        for segment in segments\n",
    "        if segment.strip()  # 过滤空段落\n",
    "    )\n",
    "\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "import traceback\n",
    "def is_valid_content_element(processed: Dict) -> Dict:\n",
    "    \"\"\"综合校验单个content元素的有效性\"\"\"\n",
    "    # 基础校验：字段完整性\n",
    "    # 优先取 'c'，若不存在则取 'title_content'，最后默认空字符串\n",
    "   \n",
    "    content_key = 'c' if 'c' in processed else 'title_content' if 'title_content' in processed else 'c'\n",
    "\n",
    "    raw_content = processed.get(content_key, '')\n",
    "    elem_type = processed.get('t', 'text') \n",
    "    \n",
    "\n",
    "    \n",
    "    # 规则1: 空内容或纯空格\n",
    "    if is_empty_content(raw_content):\n",
    "        processed[content_key] = ''\n",
    "        processed['t'] = 'text'  # 强制类型为text\n",
    "        return processed\n",
    "    \n",
    "    \n",
    "    # 规则2: 过多空白（根据不同类型调整阈值）\n",
    "    if has_excessive_whitespace(raw_content):\n",
    "        processed[content_key] = ''\n",
    "        processed['t'] = 'text'  # 强制类型为text\n",
    "        return processed\n",
    "\n",
    " \n",
    "    # --- 清理逻辑 ---\n",
    "    cleaned = clean_html_tag(clean_repeat_chars(clean_special_whitespace(raw_content)))\n",
    "  \n",
    "    processed[content_key] = cleaned  # 更新原始内容键\n",
    "    processed['t'] = elem_type  # 保留原始类型或默认值\n",
    "       \n",
    "    return processed\n",
    "\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def filter_content(content: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"过滤content列表，保留有效内容元素\"\"\"\n",
    "    filtered = []\n",
    "    for elem in content:\n",
    "        # 步骤1: 校验并处理单个元素\n",
    "        processed = is_valid_content_element(elem)\n",
    "        \n",
    "        # 步骤2: 动态判断内容键（优先'c'，其次是'title_content'）\n",
    "        content_key = 'c' if 'c' in processed else 'title_content' if 'title_content' in processed else None\n",
    "        if not content_key:\n",
    "            continue  # 无内容键，直接跳过\n",
    "        \n",
    "        # 步骤3: 检查内容是否有效（非空且非纯空格）\n",
    "        content_value = processed.get(content_key, '')\n",
    "        if content_value.strip() != '':\n",
    "            filtered.append(processed)\n",
    "            \n",
    "    return filtered\n",
    "\n",
    "def update_value(data, target_key, condition = lambda x :True, new_value =clean_special_whitespace):\n",
    "    \"\"\"\n",
    "    递归地遍历任意维的字典列表堆叠结构数据，并根据条件更新特定键的值。\n",
    "\n",
    "    :param data: 数据结构（字典或列表）\n",
    "    :param target_key: 要更新的目标键\n",
    "    :param condition: 更新条件函数\n",
    "    :param new_value: 新的值（可以是具体值或函数）\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key == target_key and condition(value):\n",
    "                if callable(new_value):\n",
    "                    data[key] = new_value(value)\n",
    "                else:\n",
    "                    data[key] = new_value\n",
    "            else:\n",
    "                update_value(value, target_key, condition, new_value)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            update_value(item, target_key, condition, new_value)\n",
    "   \n",
    "        \n",
    "def filter_content_list(row):\n",
    "    \"\"\"优化点：分离标题/段落处理，防御性类型检查，保留原始数据结构\"\"\"\n",
    "    try:\n",
    "        # 防御性获取内容列表\n",
    "        for page in row.get(\"content_list\", []):\n",
    "            valid_elements = []\n",
    "            for elem in page:\n",
    "                # 非字典或非目标类型直接保留\n",
    "                if not isinstance(elem, dict) or elem.get('type') not in ('title', 'paragraph','list'):\n",
    "                    valid_elements.append(elem)\n",
    "                    continue\n",
    "\n",
    "                # 类型分流处理\n",
    "                elem_type = elem['type']\n",
    "\n",
    "                content_data = elem.get('content')\n",
    "\n",
    "                # --- 标题类型处理 ---\n",
    "                if elem_type == 'title':\n",
    "                    # 标题内容必须是字典且包含 title_content\n",
    "                    if isinstance(content_data, dict) and 'title_content' in content_data:\n",
    "                        filtered = filter_content([content_data])  # 包装成列表\n",
    "                        # 校验返回结果有效性\n",
    "                        if filtered and isinstance(filtered, list) and len(filtered) > 0:\n",
    "                            new_content = filtered[0]\n",
    "                            # 确保标题内容非空\n",
    "                            if new_content.get('title_content', '').strip():\n",
    "                                elem['content'] = new_content\n",
    "                                valid_elements.append(elem)\n",
    "                    # 无效标题内容直接过滤\n",
    "                    continue\n",
    "\n",
    "                # --- 段落类型处理 ---\n",
    "                if elem_type == 'paragraph':\n",
    "                    # 段落内容必须是列表\n",
    "                    if isinstance(content_data, list):\n",
    "                        filtered = filter_content(content_data)\n",
    "                        # 保留非空内容\n",
    "                        if filtered and len(filtered) > 0:\n",
    "                            elem['content'] = filtered\n",
    "                            valid_elements.append(elem)\n",
    "                    # 无效段落内容直接过滤\n",
    "                    continue\n",
    "                if elem_type == 'list':\n",
    "                    update_value(content_data,'c')\n",
    "                  \n",
    "                    elem['content'] = content_data\n",
    "                   \n",
    "                    valid_elements.append(elem)\n",
    "                    \n",
    "\n",
    "\n",
    "            # 原地更新页面内容\n",
    "            page[:] = valid_elements\n",
    "        return row\n",
    "    except Exception as e:\n",
    "        row['__error'] = {\n",
    "            'code': -1,\n",
    "            'msg': f\"Content filtering failed: {str(e)}\",\n",
    "            'trace': traceback.format_exc()\n",
    "        }\n",
    "        return row\n",
    "from llm_web_kit.input.datajson import DataJson\n",
    "\n",
    "def make_content_md(row):\n",
    "    try:\n",
    "        row['content_qa'] = DataJson(row).get_content_list().to_nlp_md()\n",
    "\n",
    "        return row\n",
    "    except Exception as e2:\n",
    "        err = {\"code\":-1, f\"{row}msg\": traceback.format_exc()}\n",
    "        row['content_qa'] = ''\n",
    "        row['__error'] = err\n",
    "        return row\n",
    "\n",
    "def del_content_qa(row):\n",
    "    del row['content_qa']\n",
    "    return row\n",
    "\n",
    "from llm_web_kit.input.datajson import DataJson, StructureMapper\n",
    "def clist_filter_factory(self, field_you_want = ('paragraph')):\n",
    "    \"\"\"把content_list转化为md格式，只接受 Node 类型为 ['a', 'b'].\n",
    "    Returns:\n",
    "        str: md格式的文本内容\n",
    "    \"\"\"\n",
    "    md_blocks = []  # 每个是个DocElementType规定的元素块之一转换成的文本\n",
    "    content_lst = self._get_data()\n",
    "    for page in content_lst:\n",
    "        for content_lst_node in page:\n",
    "            if content_lst_node['type'] in field_you_want:\n",
    "                txt_content = self._StructureMapper__content_lst_node_2_md(content_lst_node)\n",
    "                if txt_content and len(txt_content) > 0:\n",
    "                    md_blocks.append(txt_content)\n",
    "    md = self._StructureMapper__md_para_splitter.join(md_blocks)\n",
    "    md = md.strip() + self._StructureMapper__text_end  # 加上结尾换行符\n",
    "    return md\n",
    "\n",
    "    \n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "#安全解析函数（包含异常捕获）\n",
    "def safe_json_loads(s):\n",
    "    try:\n",
    "        json.loads(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "# 将Python函数注册为Spark UDF\n",
    "safe_json_udf = udf(safe_json_loads, BooleanType())\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fbfa6a-8ad4-4560-b587-389e7301f41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:35:45.999732Z",
     "iopub.status.busy": "2025-03-18T02:35:45.999321Z",
     "iopub.status.idle": "2025-03-18T02:35:46.013473Z",
     "shell.execute_reply": "2025-03-18T02:35:46.013103Z",
     "shell.execute_reply.started": "2025-03-18T02:35:45.999713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'field_mappings': {'track_id': 'track_id',\n",
       "  'page_layout_type_map': {'': 'article',\n",
       "   '文章': 'article',\n",
       "   '网易': 'article',\n",
       "   '视频': 'video',\n",
       "   '腾讯网': 'article'},\n",
       "  'dataset_name': 'tencent',\n",
       "  'url': 'url',\n",
       "  'html': 'content',\n",
       "  'layout_field': 'f_name',\n",
       "  'data_source_category': 'HTML'},\n",
       " 'extractor_config': '/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc',\n",
       " 'output_template': 's3://llm-users-phdd2/jiangwenhao/article/zh-web-tencent/v002/'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version=\"002\"\n",
    "sub_dir=''\n",
    "input_paths =[f's3://private-crawl-data/zh-web-sohu/20241218_p1/']\n",
    "platform = extract_platform_from_s3_path(input_paths[0])\n",
    "platform_configs = {\n",
    "\n",
    "    \"zh-web-baijiahao\": {\n",
    "\n",
    "        \"field_mappings\": {\n",
    "            \"track_id\":\"track_id\",\n",
    "            \"page_layout_type_map\" :{\n",
    "                                \"\":\"article\",\n",
    "                                \"文章\":\"article\",\n",
    "                                \"网易\":'article',\n",
    "                                \"视频\":\"video\"\n",
    "                            },\n",
    "        \"dataset_name\": \"baijiahao\",\n",
    "        \"url\":\"url\",\n",
    "        \"html\":\"content\",\n",
    "        \"layout_field\": \"channel\",\n",
    "        \"data_source_category\":\"JSON\"\n",
    "        },\n",
    "        \"extractor_config\": \"/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc\",\n",
    "        \"output_template\": f\"s3://llm-users-phdd2/jiangwenhao/article/{platform}/{sub_dir}/v{version}/\"\n",
    "\n",
    "    },\n",
    "    \"zh-web-netease\": {\n",
    "\n",
    "        \"field_mappings\": {\n",
    "             \"track_id\":\"track_id\",\n",
    "            \"page_layout_type_map\" :{\n",
    "                                \"\":\"article\",\n",
    "                                \"文章\":\"article\",\n",
    "                                \"网易\":'article',\n",
    "                                \"视频\":\"video\"\n",
    "                            },\n",
    "        \"dataset_name\": \"net-ease\",\n",
    "        \"url\":\"url\",\n",
    "        \"html\":\"content\",\n",
    "        \"layout_field\": \"f_name\",\n",
    "        \"data_source_category\":\"HTML\"\n",
    "        },\n",
    "        \"extractor_config\": \"/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc\",\n",
    "        \"output_template\": f\"s3://llm-users-phdd2/jiangwenhao/article/{platform}/v{version}/\"\n",
    "    },\n",
    "    \"zh-web-tencent\": {\n",
    "\n",
    "        \"field_mappings\": {\n",
    "             \"track_id\":\"track_id\",\n",
    "            \"page_layout_type_map\" :{\n",
    "                                \"\":\"article\",\n",
    "                                \"文章\":\"article\",\n",
    "                                \"网易\":'article',\n",
    "                                \"视频\":\"video\",\n",
    "                                \"腾讯网\":\"article\"\n",
    "                            },\n",
    "        \"dataset_name\": \"tencent\",\n",
    "        \"url\":\"url\",\n",
    "        \"html\":\"content\",\n",
    "        \"layout_field\": \"f_name\",\n",
    "        \"data_source_category\":\"HTML\"\n",
    "        },\n",
    "        \"extractor_config\": \"/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc\",\n",
    "        \"output_template\": f\"s3://llm-users-phdd2/jiangwenhao/article/{platform}/v{version}/\"\n",
    "    },\n",
    "     \"zh-web-sohu\": {\n",
    "\n",
    "        \"field_mappings\": {\n",
    "             \"track_id\":\"track_id\",\n",
    "            \"page_layout_type_map\" :{\n",
    "                                \"\":\"article\",\n",
    "                                \"文章\":\"article\",\n",
    "                                \"网易\":'article',\n",
    "                                \"视频\":\"video\",\n",
    "                                \"搜狐网\":\"article\"\n",
    "                            },\n",
    "        \"dataset_name\": \"souhu\",\n",
    "        \"url\":\"url\",\n",
    "        \"html\":\"content\",\n",
    "        \"layout_field\": \"f_name\",\n",
    "        \"data_source_category\":\"HTML\"\n",
    "        },\n",
    "        \"extractor_config\": \"/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc\",\n",
    "        \"output_template\": f\"s3://llm-users-phdd2/jiangwenhao/article/{platform}/v{version}/\"\n",
    "    },\n",
    "    \"zh-web-sina\": {\n",
    "\n",
    "        \"field_mappings\": {\n",
    "             \"track_id\":\"track_id\",\n",
    "            \"page_layout_type_map\" :{\n",
    "                                \"\":\"article\",\n",
    "                                \"文章\":\"article\",\n",
    "                                \"网易\":'article',\n",
    "                                \"视频\":\"video\",\n",
    "                                \"搜狐网\":\"article\",\n",
    "                                \"黑猫投诉\":\"forum\",\n",
    "                                \"新浪网\":\"article\"\n",
    "                            },\n",
    "        \"dataset_name\": \"sina\",\n",
    "        \"url\":\"url\",\n",
    "        \"html\":\"content\",\n",
    "        \"layout_field\": \"f_name\",\n",
    "        \"data_source_category\":\"HTML\"\n",
    "        },\n",
    "        \"extractor_config\": \"/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc\",\n",
    "        \"output_template\": f\"s3://llm-users-phdd2/jiangwenhao/article/{platform}/v{version}/\"\n",
    "    },\n",
    "\n",
    "    \"blog_sina_com_cn\": {\n",
    "\n",
    "        \"field_mappings\": {\n",
    "             \"track_id\":\"track_id\",\n",
    "            \"page_layout_type_map\" :{\n",
    "                                \"\":\"article\",\n",
    "                                \"文章\":\"article\",\n",
    "                                \"网易\":'article',\n",
    "                                \"视频\":\"video\",\n",
    "                                \"搜狐网\":\"article\",\n",
    "                                \"黑猫投诉\":\"forum\",\n",
    "                                \n",
    "                            },\n",
    "        \"dataset_name\": \"sina_blog\",\n",
    "        \"url\":\"url\",\n",
    "        \"html\":\"html\",\n",
    "        \"layout_field\": \"f_name\",\n",
    "        \"data_source_category\":\"HTML\"\n",
    "        },\n",
    "        \"extractor_config\": \"/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc\",\n",
    "        \"output_template\": f\"s3://llm-users-phdd2/jiangwenhao/article/{platform}/v{version}/\"\n",
    "    },\n",
    "    \"DouBan\": {\n",
    "       \n",
    "        \"field_mappings\": {\n",
    "             \"track_id\":\"track_id\",\n",
    "            \"page_layout_type_map\" :{\n",
    "                                \"\":\"article\",\n",
    "                                \"文章\":\"article\",\n",
    "                                \"网易\":'article',\n",
    "                                \"视频\":\"video\",\n",
    "                                \"搜狐网\":\"article\",\n",
    "                                \"黑猫投诉\":\"forum\",\n",
    "                                \"豆瓣网\":\"\"\n",
    "                            },\n",
    "        \"dataset_name\": \"sina\",\n",
    "        \"url\":\"url\",\n",
    "        \"html\":\"html\",\n",
    "        \"layout_field\": \"f_name\",\n",
    "        \"data_source_category\":\"HTML\"\n",
    "        },\n",
    "        \"extractor_config\": \"/share/jiangwenhao/notebooks/定向子集专项/subset-spliz.jsonc\",\n",
    "        \"output_template\": f\"s3://llm-users-phdd2/jiangwenhao/article/{platform}/v{version}/\"\n",
    "    },\n",
    "}\n",
    "platform_config = platform_configs.get(platform)\n",
    "platform_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434f005-9d98-4b2d-b4e2-528b8b341ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b1d4e3-abc7-4f36-95fa-10953261ad37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:35:47.713232Z",
     "iopub.status.busy": "2025-03-18T02:35:47.713042Z",
     "iopub.status.idle": "2025-03-18T02:35:58.218030Z",
     "shell.execute_reply": "2025-03-18T02:35:58.217571Z",
     "shell.execute_reply.started": "2025-03-18T02:35:47.713217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.140.84.27:39252\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>llm_kit_cc</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa5eafb6680>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"spark_conf_name\": \"spark_4\",\n",
    "    \"skip_success_check\": True,\n",
    "    # 根据个人路径进行替换1\n",
    "    \"spark.executorEnv.LLM_WEB_KIT_CFG_PATH\": \"/share/jiangwenhao/.llm-web-kit.jsonc\",\n",
    "    \"spark.dynamicAllocation.maxExecutors\": \"400\",\n",
    "    \"spark.yarn.queue\": \"root.clean_exp\"\n",
    "}\n",
    "spark = new_spark_session(\"llm_kit_cc\", config)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ebfee19-6732-4a97-8a5e-fc876928ded0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:39:35.448812Z",
     "iopub.status.busy": "2025-03-18T02:39:35.447782Z",
     "iopub.status.idle": "2025-03-18T02:39:39.632163Z",
     "shell.execute_reply": "2025-03-18T02:39:39.631672Z",
     "shell.execute_reply.started": "2025-03-18T02:39:35.448785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "路径: s3://private-crawl-data/zh-web-tencent/20241218_p1/ → 平台: zh-web-tencent\n",
      "读取数据结束\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"路径: {input_paths[0]} → 平台: {platform}\")\n",
    "\n",
    "\n",
    "\"\"\"接收 spark 作为参数而不是持有它\"\"\"\n",
    "platform_config = platform_configs.get(platform)\n",
    "if not platform_config:\n",
    "    raise ValueError(f\"Unsupported platform: {platform}\")\n",
    "\n",
    "# Driver 端操作\n",
    "input_df = read_any_path(spark, \",\".join(input_paths), config)\n",
    "print(f\"读取数据结束\")\n",
    "# 准备 Worker 端配置\n",
    "worker_config = {\n",
    "    \"field_mappings\": platform_config.get(\"field_mappings\"),\n",
    "    \"extractor_config\": platform_config.get(\"extractor_config\")\n",
    "}\n",
    "# 分别广播不同配置\n",
    "broadcast_field_mappings = worker_config[\"field_mappings\"]\n",
    "broadcast_extractor_config_path = worker_config[\"extractor_config\"] # 广播路径\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#processed_rdd_error_filter = processed_rdd.filter(lambda x:\"__error\"  in x)\n",
    "\n",
    "#write_any_path(processed_rdd_error_filter.map(lambda x: Row(value=json_dumps(x.asDict()))).toDF(),\"s3://web-parse-hw60p/xuchao/zx-html-error/tencent_blog/v002\")\n",
    "\n",
    "\n",
    "#result_df = processed_rdd_filter.map(lambda x: Row(value=json_dumps(x.asDict()))).toDF()\n",
    "\n",
    "# write_any_path(result_df, platform_config[\"output_template\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b65a9bc-2271-4bda-a766-36306c60b06d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:39:39.633107Z",
     "iopub.status.busy": "2025-03-18T02:39:39.632948Z",
     "iopub.status.idle": "2025-03-18T02:39:39.742895Z",
     "shell.execute_reply": "2025-03-18T02:39:39.742357Z",
     "shell.execute_reply.started": "2025-03-18T02:39:39.633090Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 在filter中使用UDF生成的Column表达式\n",
    "processed_rdd_filter = input_df.filter(safe_json_udf(col(\"value\"))).rdd.map(lambda x: Row(**{**json.loads(x.value), \"filename\": x.filename})).map(\n",
    "    lambda row: transform_row(row, broadcast_field_mappings)\n",
    ").repartition(6000).filter(lambda x:\"__error\" not in x).filter(lambda x :x.html !='').mapPartitions(\n",
    "     lambda x:extract_data(\n",
    "        x,broadcast_extractor_config_path = broadcast_extractor_config_path\n",
    "    )\n",
    ").filter(lambda x:\"__error\" not in x).cache()\n",
    "#\\input_path = [\"s3://llm-users-phdd2/jiangwenhao/article/zh-web-tencent/v002/\"]\n",
    "#input_df = read_any_path(spark, \",\".join(input_path), config)\n",
    "processed_rdd_filter = processed_rdd_filter.map(lambda x :x.asDict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b8f18-7ed7-48cc-8a99-876318cd87c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00f4caca-da23-4bbe-b98c-73deb7f3b1ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:39:41.804922Z",
     "iopub.status.busy": "2025-03-18T02:39:41.804427Z",
     "iopub.status.idle": "2025-03-18T02:39:41.833369Z",
     "shell.execute_reply": "2025-03-18T02:39:41.832809Z",
     "shell.execute_reply.started": "2025-03-18T02:39:41.804901Z"
    }
   },
   "outputs": [],
   "source": [
    "filter_json_rdd = processed_rdd_filter.filter(is_plain_text)\n",
    "\n",
    "\n",
    "filter_html_empty_rdd = processed_rdd_filter.filter(lambda x : is_empty_content_list(x) and not is_plain_text(x))\n",
    "\n",
    "## 是HTML但是content_list不为空的数据集==》正常输出数据集\n",
    "filter_html_rdd = processed_rdd_filter.filter(lambda x : not is_empty_content_list(x) and not is_plain_text(x))\n",
    "\n",
    "filter_json_add_content_list_rdd = filter_json_rdd.map(lambda x : parse_text_paragraphs(x))\n",
    "\n",
    "filter_html_add_content_list_rdd = filter_html_empty_rdd.map(parse_text_paragraphs)\n",
    "\n",
    "\n",
    "\n",
    "union_rdd = filter_html_rdd.union(filter_html_add_content_list_rdd).union(filter_json_add_content_list_rdd)\n",
    "final_rdd = union_rdd.map(filter_content_list).filter( lambda x : not is_empty_content_list(x)).map(make_content_md).filter(lambda x: not  is_too_short(x['content_qa'])). \\\n",
    "filter(lambda x : not has_excessive_whitespace(x['content_qa'])).filter(lambda x : not is_url_only_content(x['content_qa'])).map(del_content_qa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f9556-0d57-48d6-bc92-0cd4ad7ffe70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810cc30-0b51-4465-a6e9-12e204ba4f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T02:39:42.689911Z",
     "iopub.status.busy": "2025-03-18T02:39:42.689450Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:>                                                     (0 + 230) / 288]"
     ]
    }
   ],
   "source": [
    "final_df = final_rdd.map(lambda x: Row(value=json_dumps(x))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e32bf-2bb0-4d26-8c98-347e732ccfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 验收数据\n",
    "#腾讯\n",
    "write_any_path(final_df, \"s3://zhuanxiang-hw60p/article/souhu/v003/\")\n",
    "#souhu\n",
    "#write_any_path(final_df, \"s3://zhuanxiang-hw60p/article/souhu/final/v002/\")\n",
    "#sina\n",
    "#write_any_path(final_df, \"s3://zhuanxiang-hw60p/article/sina/v008/\")\n",
    "#sina——blog\n",
    "#write_any_path(final_df, \"s3://zhuanxiang-hw60p/article/blog_sina_com_cn/final/v001/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68848973-92eb-4704-955f-ffcbfbbc7540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71511c-7c74-4d64-9eff-76dd393d436a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056d0ac-fd2b-42e1-b0e9-d87938d0bf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd755f9b-91d2-4dbf-af56-2f1768d9c261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d77da-61ca-436e-b032-7b0aba1e7aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python code_clean_venv (ipykernel)",
   "language": "python",
   "name": "test_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
